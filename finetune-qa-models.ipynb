{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05617b95-3258-4af3-b2a0-283fafcc9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140e13f8-37bf-4526-b7c1-41f76e251928",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = pd.read_csv('2021_10_20_products_series_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d494b46-5b01-494e-a694-13baf47b8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def read_squad(path):\n",
    "    path = Path(path)\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return contexts, questions, answers\n",
    "\n",
    "train_contexts, train_questions, train_answers = read_squad('squad/train-v2.0.json')\n",
    "val_contexts, val_questions, val_answers = read_squad('squad/dev-v2.0.json')\n",
    "\n",
    "def add_end_idx(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        gold_text = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "\n",
    "        # sometimes squad answers are off by a character or two – fix this\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            answer['answer_end'] = end_idx\n",
    "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "            answer['answer_start'] = start_idx - 1\n",
    "            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
    "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "            answer['answer_start'] = start_idx - 2\n",
    "            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
    "\n",
    "add_end_idx(train_answers, train_contexts)\n",
    "add_end_idx(val_answers, val_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a5b9a5f-edd7-4579-9c8b-a428005c0777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('singing and dancing', 19)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_contexts[1][207:226],len('singing and dancing')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ca68168-96f3-491b-bfaf-737b4f6da9d5",
   "metadata": {},
   "source": [
    "train_contexts[1],train_questions[1], train_answers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db1f5278-581e-4538-b315-77589fdcceb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'in the late 1990s', 'answer_start': 269, 'answer_end': 286},\n",
       " {'text': 'singing and dancing', 'answer_start': 207, 'answer_end': 226},\n",
       " {'text': '2003', 'answer_start': 526, 'answer_end': 530},\n",
       " {'text': 'Houston, Texas', 'answer_start': 166, 'answer_end': 180},\n",
       " {'text': 'late 1990s', 'answer_start': 276, 'answer_end': 286},\n",
       " {'text': \"Destiny's Child\", 'answer_start': 320, 'answer_end': 335},\n",
       " {'text': 'Dangerously in Love', 'answer_start': 505, 'answer_end': 524},\n",
       " {'text': 'Mathew Knowles', 'answer_start': 360, 'answer_end': 374},\n",
       " {'text': 'late 1990s', 'answer_start': 276, 'answer_end': 286},\n",
       " {'text': 'lead singer', 'answer_start': 290, 'answer_end': 301}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301e2156-68b8-4016-a335-340cc94b6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = myData.loc[:,['omsid','product_name','series_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ca1360-db73-415c-a609-8545a46e0386",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData.loc[:,'answer_start'] = \"N\"\n",
    "myData.loc[:,'answer_end'] = \"N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47decbd0-3689-45ae-9b37-6c172ddfc9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of 29675, 23391 are in the title\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i, row in myData.iterrows():\n",
    "    if row.series_name in row.product_name:\n",
    "        myData.loc[i,'answer_start'] = row.product_name.index(row.series_name)\n",
    "        myData.loc[i,'answer_end'] = myData.loc[i,'answer_start'] + len(row.series_name)\n",
    "        counter += 1\n",
    "print(f\"out of {myData.shape[0]}, {counter} are in the title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8102f90-3825-475f-9d67-298728e9219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData_cleaned = myData.loc[myData.loc[:,'answer_start'] != \"N\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4bde68-5ae1-4117-ac9a-86dccf08f1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>omsid</th>\n",
       "      <th>product_name</th>\n",
       "      <th>series_name</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>315696655</td>\n",
       "      <td>AN-4500 and AN-4512 Aria Single Handle Single ...</td>\n",
       "      <td>Aria</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>309122846</td>\n",
       "      <td>Hilo 8 in. Widespread 2-Handle Bathroom Faucet...</td>\n",
       "      <td>Hilo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>309122896</td>\n",
       "      <td>Hilo 4 in. Centerset 2-Handle Bathroom Faucet ...</td>\n",
       "      <td>Hilo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>309122853</td>\n",
       "      <td>Hilo 8 in. Widespread 2-Handle Bathroom Faucet...</td>\n",
       "      <td>Hilo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>309122906</td>\n",
       "      <td>Hilo 4 in. Centerset 2-Handle Bathroom Faucet ...</td>\n",
       "      <td>Hilo</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29670</th>\n",
       "      <td>313341432</td>\n",
       "      <td>Colinet 2-Handle Wall Mount Bathroom Faucet Tr...</td>\n",
       "      <td>Colinet</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29671</th>\n",
       "      <td>313341429</td>\n",
       "      <td>Colinet 2-Handle Wall Mount Bathroom Faucet Tr...</td>\n",
       "      <td>Colinet</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29672</th>\n",
       "      <td>313341430</td>\n",
       "      <td>Colinet 2-Handle Wall Mount Bathroom Faucet Tr...</td>\n",
       "      <td>Colinet</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29673</th>\n",
       "      <td>313341434</td>\n",
       "      <td>Colinet 2-Handle Wall Mount Bathroom Faucet Tr...</td>\n",
       "      <td>Colinet</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29674</th>\n",
       "      <td>313341441</td>\n",
       "      <td>Colinet 2-Handle Wall Mount Bathroom Faucet Tr...</td>\n",
       "      <td>Colinet</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23391 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           omsid                                       product_name  \\\n",
       "4      315696655  AN-4500 and AN-4512 Aria Single Handle Single ...   \n",
       "5      309122846  Hilo 8 in. Widespread 2-Handle Bathroom Faucet...   \n",
       "6      309122896  Hilo 4 in. Centerset 2-Handle Bathroom Faucet ...   \n",
       "7      309122853  Hilo 8 in. Widespread 2-Handle Bathroom Faucet...   \n",
       "8      309122906  Hilo 4 in. Centerset 2-Handle Bathroom Faucet ...   \n",
       "...          ...                                                ...   \n",
       "29670  313341432  Colinet 2-Handle Wall Mount Bathroom Faucet Tr...   \n",
       "29671  313341429  Colinet 2-Handle Wall Mount Bathroom Faucet Tr...   \n",
       "29672  313341430  Colinet 2-Handle Wall Mount Bathroom Faucet Tr...   \n",
       "29673  313341434  Colinet 2-Handle Wall Mount Bathroom Faucet Tr...   \n",
       "29674  313341441  Colinet 2-Handle Wall Mount Bathroom Faucet Tr...   \n",
       "\n",
       "      series_name answer_start answer_end  \n",
       "4            Aria           20         24  \n",
       "5            Hilo            0          4  \n",
       "6            Hilo            0          4  \n",
       "7            Hilo            0          4  \n",
       "8            Hilo            0          4  \n",
       "...           ...          ...        ...  \n",
       "29670     Colinet            0          7  \n",
       "29671     Colinet            0          7  \n",
       "29672     Colinet            0          7  \n",
       "29673     Colinet            0          7  \n",
       "29674     Colinet            0          7  \n",
       "\n",
       "[23391 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ffec01a-80f1-4a7f-82bf-d05a7d5d61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e08b12b-a2e6-4165-ba8d-fdbfabefbad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(myData_cleaned, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02164b9c-b597-4a7e-b3c1-c3f0d513574e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae5c4902-ce75-41c5-8e87-8d4de30819b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answers, train_contexts, train_questions = [], [], []\n",
    "for i, row in train.iterrows():\n",
    "    train_contexts.append(row.product_name)\n",
    "    train_answers.append({'text': row.series_name, 'answer_start': row.answer_start, 'answer_end': row.answer_end})\n",
    "    train_questions.append('What is the series name of this product?')\n",
    "    \n",
    "test_answers, test_contexts, test_questions = [], [], []\n",
    "for i, row in test.iterrows():\n",
    "    test_contexts.append(row.product_name)\n",
    "    test_answers.append({'text': row.series_name, 'answer_start': row.answer_start, 'answer_end': row.answer_end})\n",
    "    test_questions.append('What is the series name of this product?')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "384f6b3d-677e-4359-9186-4d5d06abfb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18712,\n",
       " 4679,\n",
       " [{'text': 'Meridian', 'answer_start': 0, 'answer_end': 8},\n",
       "  {'text': 'Decora Smart', 'answer_start': 0, 'answer_end': 12},\n",
       "  {'text': 'Surge', 'answer_start': 0, 'answer_end': 5},\n",
       "  {'text': 'Diva', 'answer_start': 0, 'answer_end': 4},\n",
       "  {'text': 'Claro', 'answer_start': 0, 'answer_end': 5},\n",
       "  {'text': 'Riverby', 'answer_start': 0, 'answer_end': 7},\n",
       "  {'text': 'Ashlyn', 'answer_start': 0, 'answer_end': 6},\n",
       "  {'text': 'Builders', 'answer_start': 0, 'answer_end': 8},\n",
       "  {'text': 'Woodhurst', 'answer_start': 0, 'answer_end': 9},\n",
       "  {'text': 'Kaiser', 'answer_start': 0, 'answer_end': 6}])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_answers), len(test_answers), test_answers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "952535d6-de36-4e64-9b16-fec53451ad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Decora Smart'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_contexts[1][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ae0d700a-87e3-42d8-9c4e-4eebff279a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18712"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import DistilBertTokenizerFast\n",
    "# tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-uncased')\n",
    "len(train_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1f7b9e9-fc13-4ef3-8eea-aac178b53b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md           merges.txt         special_tokens_map.json\n",
      "config.json         pytorch_model.bin  tokenizer_config.json\n",
      "flax_model.msgpack  rust_model.ot      vocab.json\n"
     ]
    }
   ],
   "source": [
    "ls roberta-base-squad2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b64bd89-6211-42f7-b8f3-f07d22cfa573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9e8842db-bd26-4358-838f-b30adf8694f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "        # if None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a192d802-c492-4fe4-857f-3432a688d6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_encodings.char_to_token(1, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "698aeec9-6768-408b-9454-7522f966d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# build datasets for both our training and validation sets\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd88247e-510a-4f90-ac0c-98753f300267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "665c931e-8b65-4ca3-9e0a-4887c2e0b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1170/1170 [01:54<00:00, 10.18it/s, loss=0.0529] \n",
      "Epoch 1: 100%|██████████| 1170/1170 [01:55<00:00, 10.15it/s, loss=0.00708] \n",
      "Epoch 2: 100%|██████████| 1170/1170 [01:55<00:00, 10.14it/s, loss=0.00322] \n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# setup GPU/CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# move model over to detected device\n",
    "model.to(device)\n",
    "# activate training mode of model\n",
    "model.train()\n",
    "# initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# initialize data loader for training data\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "    # setup loop (we use tqdm for the progress bar)\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all the tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        # train model on batch and return outputs (incl. loss)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        # extract loss\n",
    "        loss = outputs[0]\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "666bd3a1-fdc5-4c4d-8454-4e43937b3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "898cd8a8-7ec1-47e0-b161-6110ef6a9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b52166b-1c6b-4648-a9e7-454af249bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "for i, a in enumerate(val_loader):\n",
    "    #images = a.to(device)\n",
    "\n",
    "    #print(i, a.keys())\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "566e075b-13c4-429c-8349-35251de6416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is the series name of this product?\"\n",
    "#qa(question=question, context=test.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7105c41b-dcb1-44be-8e43-6dd88a3b64be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SquadDataset at 0x7f05aac78910>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ddef6a3c-bec3-456d-bd53-17cd400f015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch model out of training mode\n",
    "model.eval()\n",
    "# initialize validation set data loader\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "# initialize list to store accuracies\n",
    "acc = []\n",
    "# loop through batches\n",
    "all_preds, all_truths = [],[]\n",
    "for batch in val_loader:\n",
    "    # we don't need to calculate gradients as we're not training\n",
    "    with torch.no_grad():\n",
    "        # pull batched items from loader\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        # we will use true positions for accuracy calc\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        # make predictions\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        # pull prediction tensors out and argmax to get predicted tokens\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        # calculate accuracy for both and append to accuracy list\n",
    "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
    "        pred_answer_batch = [ tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[x][start_pred[x]:end_pred[x]+1])) for x in range(input_ids.shape[0])]\n",
    "        true_answer_batch = [ tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[x][start_true[x]:end_true[x]+1])) for x in range(input_ids.shape[0])]\n",
    "        all_preds.extend(pred_answer_batch)\n",
    "        all_truths.extend(true_answer_batch)\n",
    "# calculate average accuracy in total\n",
    "acc = sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4b154930-41ed-438c-8c7a-cd306cfec69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_answer_batch == true_answer_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f3705b10-17a4-4d77-8e3d-1778356b0c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9805513998717674"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.sum(np.array(all_truths) == np.array(all_preds))/len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f4cebe17-e752-4d10-9bac-0a77d6fe690b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('distilbert-custom/tokenizer_config.json',\n",
       " 'distilbert-custom/special_tokens_map.json',\n",
       " 'distilbert-custom/vocab.txt',\n",
       " 'distilbert-custom/added_tokens.json',\n",
       " 'distilbert-custom/tokenizer.json')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"distilbert-custom/\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2af95960-7f4a-418e-8cb1-268d51fc747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "\n",
    "model_path = 'distilbert-custom/'\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(model_path)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349bbc4a-a743-456a-9797-fccc7499ba9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33208851-6d68-481b-b98d-79b14af90e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31dabf9-6860-47f3-8323-cfb2b921a4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "common-cu110.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m87"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
